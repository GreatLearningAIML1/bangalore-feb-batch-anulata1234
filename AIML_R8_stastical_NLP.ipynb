{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Confirmation Bias and Filter Bubbles\n\n*Confirmation Bias* is the phenomenon where people tend to seek out information that appears to confirm their existing opinions. On social media this can lead *filter bubbles*, where people only read posts from people who share their oppinions, thus leading to online debates becomming highly polarized, hostile and unconstructive. It is thought that recommendation algorithms may worsten this problem. In this notebook, I will try to see if it is possible to use NLP algorithms to find ways to create constructive dialogue between people with different opinions.  I'll test my ideas using the Blog Authorship corpus."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gensim\nimport nltk.sentiment\nimport re\nimport tqdm\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/blog-authorship-corpus/blogtext.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How do we quantify an opinion?\nWe can see an opinion as being how somebody feels about a given subject. I like apples, so anything I write about apples is likely to be positive. Somebody who dislike apples is likely to write negative things about them.\n\nLet's start by quantifying the subjects people discuss in the Blog Authorship Corpus, using LogEntropy and Latent Semantic Indexing."},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence_splitter=re.compile(\"\"\"[.?!]['\"]*\\s+\"\"\",re.UNICODE)\nSplitWords=re.compile(\"\"\"\\W+\"\"\",re.UNICODE)\ndef tokenize(document):\n    \"\"\"For a document, returns a list of tokens.\n       For a corpus (iterable of documents), returns a generator of tokenized documents.\"\"\"\n    result = []\n    for sentence in sentence_splitter.split(document.lower()):\n        words=SplitWords.split(sentence)\n        result.extend(words)\n    return result\n\nclass Tokenizer(object):\n    def __init__(self,corpus):\n        self.corpus = corpus\n    \n    def __iter__(self):\n        for document in tqdm.tqdm(self.corpus):\n            yield tokenize(document)\n\nclass bow(object):\n    def __init__(self,corpus):\n        self.tokens = Tokenizer(corpus)\n        self.dictionary = gensim.corpora.dictionary.Dictionary(self.tokens)\n    \n    def __iter__(self):\n        for doc in self.tokens:\n            yield self.dictionary.doc2bow(doc)\n\nprint(\"Building dictionary\")\nfrequencies = bow(data['text'].values)\nprint(\"Training LogEntropy model\")\nweights = gensim.models.logentropy_model.LogEntropyModel(frequencies)\n\nprint(\"Training LSI model\")\nlsi = gensim.models.LsiModel(weights[frequencies],256,frequencies.dictionary)\n\ndef transform(corpus):\n    return gensim.matutils.corpus2dense(lsi[weights[corpus]],\n                                       256).T\n\nvader=nltk.sentiment.vader.SentimentIntensityAnalyzer()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's quantify each author's opinions. For each blog post, we'll multiply the LSI vector by the sum of the polarity scores for the sentences in the post, to get an idea of how the author feels about the subjects discussed in the post. We then sum over all the posts for a given author to get a vector that represents their opinions."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Transforming corpus\")\nvectors = pd.DataFrame(transform(frequencies),\n                      index = pd.MultiIndex.from_tuples(data['id'].items()))\nvectors.index.names=('uri','id')\nprint(\"Calculating sentiments\")\nsentiments = pd.Series([sum((emotion['compound'] \n                             for emotion in (vader.polarity_scores(sentence)\n                                             for sentence in sentence_splitter.split(document))))\n                        for document in data['text'].values],\n                       index = pd.MultiIndex.from_tuples(data['id'].items()))\nsentiments.index.names=('uri','id')\nprint(\"Calculating opinions\")\nopinions = vectors.mul(sentiments,\n                      axis='index').groupby(level='id').sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Differences of opinion\n\nNow let's find some authors who have very different opinions. Taking the vector cosine of the opinion vectors for each pair of authors, let's find some authors who have large negative scores with respect to each other."},{"metadata":{"trusted":true},"cell_type":"code","source":"norms = opinions.apply(np.linalg.norm,\n                      axis=1,\n                      result_type='reduce')\ndef similarity(opinions,norms):\n    result = []\n    for user in tqdm.tqdm(opinions.index):\n        others = opinions.loc[opinions.index>user]\n        dotprod = others.mul(opinions.loc[user],\n                            axis='columns').sum(axis=1)\n        cosine = dotprod/(norms.loc[norms.index>user]*norms[user])\n        cosine.index=[(user,other) for other in cosine.index]\n        result.append(cosine[cosine<0])\n    return pd.concat(result)\n\nsimilar_users = similarity(opinions,norms)\nsimilar_users.nsmallest(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_posts(user):\n    for (uid,row) in data.loc[data['id']==user].iterrows():\n        print(uid,row['text'])\n        \nshow_posts(3963763)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_posts(3294597)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Finding common ground\nI like apples, but I have a fried who really dislikes them. Given that our opinions on apples are so different, why are we friends? Well, we have a hobby in common. Generally, I find that if I start off with some common ground with somebody, out differences of opinion don't matter, but if I encounter an opinion that I find hostile from a stranger, I'm more likely to block them.\n\nIf we take the element-wise product of the opinion vectors from two users, those elements where is it is positive correspond to the subjects on which they are most likely to agree. We can then find posts about these subjects by each author and recommend them to the other, thus introducing people whose opinions may generally be different through their common ground."},{"metadata":{"trusted":true},"cell_type":"code","source":"def common_ground(user0,user1):\n    mask = (opinions.loc[user0]*opinions.loc[user1]).apply(lambda x:1.0 if x>0 else 0)\n    targets = vectors.xs(user1,level='id')**2.0\n    return (targets.dot(mask)/targets.sum(axis=1)).sort_values()\ncommon_ground(3963763,3294597)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[576267,'text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"common_ground(3294597,3963763)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[206750,'text']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Video Commentary](https://youtu.be/1VKVFJ3pdJw)"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}